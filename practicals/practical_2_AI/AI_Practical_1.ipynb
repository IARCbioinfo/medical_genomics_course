{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "811c9a9d-f0ee-4893-ab28-03a22deb232e",
   "metadata": {},
   "source": [
    "This practical is loosely based on the first Trident tutorial which can be found [here](https://github.com/mahmoodlab/TRIDENT/blob/main/tutorials/1-Step-by-Step-Patch-Feature-Extraction-with-Trident.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0924ddd-6bd2-4067-b593-11f80688fdb7",
   "metadata": {},
   "source": [
    "# Practical 1: Whole slide images preprocessing\n",
    "Whole slide images (WSIs) are challenging to process due to their very high resolution (generally 100,000 x 100,000 px or more) and various artifacts (different staining methods, noisy background, etc.). The usual pipeline to extract a computer-friendly vector representation of a WSI is as follows:\n",
    "1. Segmentation: separating the tissue from the background.\n",
    "2. Coordinate extraction: cutting the segmented WSI into smaller tiles, usually 512 x 512 px or 256 x 256 px at 20x magnification.\n",
    "3. Tile embedding: generating a vector representation of each tile\n",
    "4. Slide embedding: based on its tile embeddings, generating a vector representation of each WSI.\n",
    "   \n",
    "[Trident](https://github.com/mahmoodlab/TRIDENT/tree/main) is a python library which provides state of the art (SOTA) models for step 1, 3, and 4. Each step of the pipeline can be done through a single command line. For the purpose of this practical, all models used will be available offline. If you want to use them on your own after the pratical, you need to create an account on hugging face and request access to them ([here](https://huggingface.co/MahmoodLab/conchv1_5) for CONCH v 1.5, [there](https://huggingface.co/MahmoodLab/abmil.base.conch_v15.pc108-24k) for Feather and [there](https://huggingface.co/MahmoodLab/TITAN) for Titan).\n",
    "If you download Trident, it is also possible to do all the steps at once, on a batch of slides with a single command line. For example, to generate feather slide embeddings of the WSIs stored in `<your/wsi/dir>` and save them into `your/output/dir`, this would be:\n",
    "\n",
    "`python run_batch_of_slides.py --task all --wsi_dir your/wsi/dir --job_dir your/output/dir --slide_encoder feather --mag 20 --patch_size 512`.\n",
    "\n",
    "Here, `task --all` indicates that you want to perform step 1 to 4, `--slide_encoder feather` says that you will use the slide encoder feather, with a magnification of `--mag 20` and a tile size of `--patch_size 512`\n",
    "\n",
    "Given that this pratical is intended as a demo of Trident, we will instead work step by step on a single, but challenging, WSI taken from TCGA-MESO (case ID [\t\n",
    "TCGA-MQ-A6BQ](https://portal.gdc.cancer.gov/cases/d3a6accc-5c45-4e70-baf5-2188af53e0db), Epitehlioid mesothelioma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979ff2cf-0c16-4d6b-9881-d548754065fe",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "data_dir = \"/data/Training-MG/files/data/AI_praticals_2025/AI_pratical_1_trident\"\n",
    "slide_name = \"TCGA-MQ-A6BQ-01Z-00-DX1.72BF21E4-17D6-436B-AAD9-7960342894F4\"\n",
    "Image(filename=f\"{data_dir}/hest/thumbnails/{slide_name}.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dd4806-591b-4b86-8ee9-1dc16e064dbc",
   "metadata": {},
   "source": [
    "⚠️ Because this pratical is only two hours long and some things are very long to compute on CPU, we replace them with placeholder methods below.\n",
    "If you want to test the true methods after the pratical on a GPU, just comment the lines of code below and run your code as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d4c419-4838-4310-9721-3fd1107b2927",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(f\"{data_dir}/utils\")\n",
    "from monkey_patch import segment_tissue, extract_patch_features, extract_slide_features\n",
    "from trident.wsi_objects.OpenSlideWSI import OpenSlideWSI\n",
    "\n",
    "OpenSlideWSI.segment_tissue = segment_tissue\n",
    "OpenSlideWSI.extract_patch_features = extract_patch_features\n",
    "OpenSlideWSI.extract_slide_features = extract_slide_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fbf9dd-7207-4c47-9cef-2f68f0deebf3",
   "metadata": {},
   "source": [
    "## 1. Segmentation\n",
    "This step will separate the tissue from the background.\n",
    "Note that if you use the Trident repo on your own later on, you can also do this step with a batch of WSIs with the following command line:\n",
    "`python run_batch_of_slides.py --task seg --wsi_dir your/wsi/dir --job_dir your/output/dir --segmenter hest`\n",
    "This will run the segmentation on the batch of WSIs using Hest segmenter (`--segmenter hest`). The flag `--remove-artifacts` can optionnally be added to remove artifacts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2830884e-c6f1-4b43-9b23-53328ecce735",
   "metadata": {},
   "source": [
    "First, let's load the slide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba2fbe9-4ddb-4f5c-96c7-9ebd8d4d3d47",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from trident import load_wsi\n",
    "slide = load_wsi(slide_path=f\"{data_dir}/slide/{slide_name}.svs\", lazy_init=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84df05ac-cc6b-4d9b-994b-c487eabcbf8f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Now, let's load the segmentation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9690a465-25ff-4c58-9fe9-26ac3aebbbce",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from trident.segmentation_models import segmentation_model_factory\n",
    "segmentation_model = segmentation_model_factory(model_name=\"hest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080d1df1-40f7-493e-a41f-a357dc1f3b41",
   "metadata": {},
   "source": [
    "If you want to see what HEST looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa0564c-2853-433d-a03f-e9559216d6e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "segmentation_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26080e0-0e00-41be-9198-9cc407bcf834",
   "metadata": {},
   "source": [
    "We can now segment the slide with the loaded model, at magnification 20x, and store them in a `trident_processed` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49415c64-f9dd-4594-8d06-016ce0beb90d",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "job_dir = \"./trident_processed\"\n",
    "slide.segment_tissue(\n",
    "    segmentation_model=segmentation_model,\n",
    "    target_mag=20,\n",
    "    job_dir=job_dir,\n",
    "    holes_are_tissue=True,\n",
    "    device='cpu',\n",
    "    num_workers=8,\n",
    "    verbose=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5038acf-c430-41ec-a3e0-8774237f36e6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Let's have a look at the segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116ad753-017b-4f23-8784-6af113ec6044",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=f\"{job_dir}/contours/{slide_name}.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b180e02b-3b77-4edd-801c-3e4276807593",
   "metadata": {},
   "source": [
    "What do you think of the quality of the segmentation? How can it be improved?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764538e2-f411-47ff-a603-e1869d9e87c4",
   "metadata": {},
   "source": [
    "By default, the segmenter consider holes as tissue. What happens if we set it to False?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bdc8da-0de3-4e6d-8303-725667f6a386",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "job_dir_no_holes = \"./trident_processed_no_holes\"\n",
    "slide_no_holes = copy.copy(slide)\n",
    "slide_no_holes.segment_tissue([...])  # Complete this code to rerun the segmentation and remove tiles containing holes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da59c5e9-484a-417e-b8c9-64c9c2d2d79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=f\"{job_dir_no_holes}/contours/{slide_name}.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301cf8bf-75e3-450f-bf82-c85c14184556",
   "metadata": {},
   "source": [
    "We can try to use an additional artifact remover to get rid of the tiles with penmarks.\n",
    "This model is named `grandqc_artifact`. It can be loaded in the same way as the segmentation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2572b3b-f9cc-4a18-a187-55dd0753ad55",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "artifact_remover_model = segmentation_model_factory(model_name=[...], remove_penmarks_only=True) # Complete this code to load grandqc_artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cfd876-7e06-48d7-8908-c96325cfbf1c",
   "metadata": {},
   "source": [
    "If you want to see what grandQC_artifact looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277f43d4-74a6-4dd7-9fd6-54c6ec79f866",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "artifact_remover_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cd938e-1bfa-464c-8b3c-da98ef6b8b75",
   "metadata": {},
   "source": [
    "We now need to do a second pass of segment_tissue using the `artifact_remover_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b28365-3436-41f0-b56f-5a5c237a8540",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_dir_no_pen = \"./trident_processed_no_pen\"\n",
    "slide_no_pen = copy.copy(slide)\n",
    "slide_no_pen.segment_tissue([...]) # Complete this code to rerun the segmentation and remove tiles containing penmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4796af05-2818-4514-86c2-98f58d9efd60",
   "metadata": {},
   "source": [
    "Let's have a look at the artifact removal. Is this better than the initial result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56784149-9c60-4cae-ad87-5635e4b29caf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Image(filename=f\"{job_dir_no_pen}/contours/{slide_name}.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e0d9f1-9a65-433f-874f-ae22662f51d1",
   "metadata": {},
   "source": [
    "## 2. Tiling\n",
    "This step will split the WSI into smaller tiles.\n",
    "Note that if you use the Trident repo on your own later on, you can also do this step with a batch of WSIs with the following command line:\n",
    "`python run_batch_of_slides.py --task coords --wsi_dir your/wsi/dir --job_dir your/output/dir --mag 20 --patch_size 512 --overlap 0`\n",
    "This will create tiles of size 512 x 512 px at 20x magnification, with 0px overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a039619b-fc71-47d5-b1a8-89002a7c48fe",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "job_dir = \"./trident_processed\"\n",
    "overlap = 0\n",
    "coords_dir = f\"{job_dir}/20x_512px_{overlap}px_overlap\"\n",
    "# We perform the tiling\n",
    "coords_path = slide.extract_tissue_coords(\n",
    "    target_mag=20,\n",
    "    patch_size=512,\n",
    "    min_tissue_proportion=0.,\n",
    "    save_coords=coords_dir,\n",
    "    overlap=overlap\n",
    ")\n",
    "# And visualise it\n",
    "viz_coords_path = slide.visualize_coords(\n",
    "    coords_path=coords_path,\n",
    "    save_patch_viz=f\"{coords_dir}/coord_visualization\",\n",
    ")\n",
    "print(f\"Tissue coordinates extracted and saved to {viz_coords_path}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a413334c-597d-4a71-b95d-b3ba232c28ce",
   "metadata": {},
   "source": [
    "Now, let's look at the tiling results. Did we get a lot of tiles using a shape of 512 x 512 px ? Does this take the previous segmentation into account?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ecf573-de7c-45a4-a04f-65e52b35406c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(viz_coords_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d91baf-ae9c-4bba-9173-bbe784852b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from lovely_numpy import lo\n",
    "\n",
    "with h5py.File(f\"./trident_processed/20x_512px_0px_overlap/patches/{slide_name}_patches.h5\") as f: # Add the h5 filename you found above\n",
    "    coords = f[\"coords\"][:] # Extract the coordinates of the patches embeddings as a numpy array\n",
    "print(lo(coords)) # Pretty display of the np array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a538d14-08a3-49d6-ae38-58a46a03a3b8",
   "metadata": {},
   "source": [
    "Let's try this with some overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14130e9b-1b6b-4a87-841f-d0da25d7532d",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap = [...] # Change to the overlap value of your choice. It must be an positive integer lower than 512.\n",
    "coords_dir_overlap = f\"{job_dir}/20x_512px_{overlap}px_overlap\"\n",
    "# We perform the tiling\n",
    "coords_path = slide.extract_tissue_coords(\n",
    "    target_mag=20,\n",
    "    patch_size=512,\n",
    "    save_coords=coords_dir_overlap,\n",
    "    overlap=overlap\n",
    ")\n",
    "# And visualise it\n",
    "viz_coords_path = slide.visualize_coords(\n",
    "    coords_path=coords_path,\n",
    "    save_patch_viz=f\"{coords_dir_overlap}/coord_visualization\",\n",
    ")\n",
    "print(f\"Tissue coordinates extracted and saved to {viz_coords_path}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608113d3-71b2-4733-86c2-e6d5b1a22c3c",
   "metadata": {},
   "source": [
    "What changes in the tiling?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a210cd-ff95-4459-b53d-e3372e51575a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(viz_coords_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b43da0f-1d4a-4e7a-b26a-03a5e0a128fc",
   "metadata": {},
   "source": [
    "Now, complete both code cells below to compute the tiling for the segmentation version without holes and without penmarks.\n",
    "We will use them in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fe6c64-bd3b-4420-8542-0f0ed6c2b59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap = 0\n",
    "coords_dir_no_holes = f\"{job_dir_no_holes}/20x_512px_{overlap}px_overlap\"\n",
    "# Complete the code below to perform the tiling\n",
    "coords_path_no_holes = slide_no_holes.extract_tissue_coords(\n",
    "    [...]\n",
    ")\n",
    "# Complete the code below to visualise it\n",
    "viz_coords_path_no_holes = slide_no_holes.visualize_coords(\n",
    "    [...]\n",
    ")\n",
    "print(f\"Tissue coordinates extracted and saved to {viz_coords_path_no_holes}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7737c5-a8eb-4cef-b792-66190a132510",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap = 0\n",
    "coords_dir_no_pen = f\"{job_dir_no_pen}/20x_512px_{overlap}px_overlap\"\n",
    "# Complete the code below to perform the tiling\n",
    "coords_path_no_pen = slide_no_pen.extract_tissue_coords(\n",
    "    [...]\n",
    ")\n",
    "# Complete the code below to visualise it\n",
    "viz_coords_path_no_pen = slide_no_pen.visualize_coords(\n",
    "    [...]\n",
    ")\n",
    "print(f\"Tissue coordinates extracted and saved to {viz_coords_path_no_pen}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfc92bd-557b-480f-a891-e96d99598025",
   "metadata": {},
   "source": [
    "## 3. Tile embedding\n",
    "This step will transform the tiles into vector representations: the tile embeddings.\n",
    "Note that if you use the Trident repo on your own later on, you can also do this step with a batch of WSIs with the following command line:\n",
    "`python run_batch_of_slides.py --task feat --wsi_dir your/wsi/dir --job_dir your/output/dir --mag 20 --patch_size 512 --patch_encoder conch_v15`\n",
    "This will create tile embeddings using the foundation model CONCH v 1.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bc619b-973a-4c8b-a840-efadbaf9f0e0",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from trident.patch_encoder_models import encoder_factory\n",
    "from trident.patch_encoder_models import encoder_registry as patch_encoder_registry\n",
    "# We load CONCH v1.5\n",
    "encoder = encoder_factory(\"conch_v15\")\n",
    "# We set it to evaluation mode, as we do not intend to fine tune it.\n",
    "encoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04472306-8da8-477f-aa27-206f6a53d108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The results will be saved into ./trident_processed/20x_512px_0px_overlap/features_conch_v15\n",
    "tiles_path = f\"{coords_dir}/features_conch_v15\"\n",
    "coords_path = f\"{coords_dir}/patches/{slide.name}_patches.h5\"\n",
    "slide.extract_patch_features(\n",
    "        patch_encoder=encoder,\n",
    "        coords_path=coords_path,\n",
    "        save_features=tiles_path,\n",
    "        batch_limit=16\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d5f3d9-5c8a-4d35-8ddb-9c06d13ab38a",
   "metadata": {},
   "source": [
    "Now, let's look at the content of the folder. What is there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f7e6c2-62d6-4391-b357-64392df6d9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ./trident_processed/20x_512px_0px_overlap/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70402833-0cf9-4375-befb-fdb68a7deaab",
   "metadata": {},
   "source": [
    "Let's look inside the visualization folder listed above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "571440db-a66a-4b37-ab49-d2c714bdf3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCGA-MQ-A6BQ-01Z-00-DX1.72BF21E4-17D6-436B-AAD9-7960342894F4.jpg\n"
     ]
    }
   ],
   "source": [
    "!ls ./trident_processed_no_holes/20x_512px_0px_overlap/visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2686b1d-02d3-46ff-ad6f-3e9c72eaf931",
   "metadata": {},
   "source": [
    "Let's look inside the jpg file listed above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70729ca3-b466-45d4-9505-6804ade0ea18",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=f\"./trident_processed_no_holes/20x_512px_0px_overlap/visualization/{slide_name}.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fd9555-a439-44fa-b34f-0177290ac494",
   "metadata": {},
   "source": [
    "How many tiles were encoded for this slide? Does this match the number of tiles from the segmentation step? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3345d479-594d-49a6-b073-fe37e2aae765",
   "metadata": {},
   "source": [
    "Let's repeat the process using the segmentation where we removed tiles with holes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39901fa-a5c2-435d-b1e7-610a7d1e0b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The results will be saved into ./trident_processed_no_holes/20x_512px_0px_overlap/features_conch_v15\n",
    "tiles_path_no_holes = [...]\n",
    "coords_path_no_holes = [...]\n",
    "# Fill in the code below to extract patch features using a segmentation where holes are removed\n",
    "slide_no_holes.extract_patch_features([...])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a659d1-3ad5-4925-b8a9-c48f5445df82",
   "metadata": {},
   "source": [
    "Now, let's look at the content of the folder. What is there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57a6683c-5eee-4573-b233-93e11becba5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_conch_v15  patches  slide_features_feather  visualisation\n"
     ]
    }
   ],
   "source": [
    "!ls ./trident_processed_no_holes/20x_512px_0px_overlap/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f5253e-df8a-4bf9-803f-669b0e87424f",
   "metadata": {},
   "source": [
    "Let's look inside the visualization folder listed above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cd6676f-5cb1-42a5-a5a6-d47ec15c47a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCGA-MQ-A6BQ-01Z-00-DX1.72BF21E4-17D6-436B-AAD9-7960342894F4.jpg\n"
     ]
    }
   ],
   "source": [
    "!ls ./trident_processed_no_holes/20x_512px_0px_overlap/visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff76c5a4-01d4-4637-95d0-31c63fdc58f9",
   "metadata": {},
   "source": [
    "Let's look inside the jpg file listed above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd4215e-5019-474f-a9cb-612c330db64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=[...])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8e584f-4448-420a-81b4-93d6224abe9f",
   "metadata": {},
   "source": [
    "How many tiles were encoded for this slide? How many where removed compared to the classical segmentation? why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cbcfdb-111e-4c99-a0de-f2829ca82e0f",
   "metadata": {},
   "source": [
    "Let's repeat the process using the segmentation where we removed tiles with penmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949ca96e-31c8-465d-977a-f66d35ddd5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the code below to extract patch features using a segmentation where holes are removed\n",
    "# The results will be saved into ./trident_processed_no_pen/20x_512px_0px_overlap/features_conch_v15\n",
    "tiles_path_no_pen = [...]\n",
    "coords_path_no_pen = [...]\n",
    "slide_no_pen.extract_patch_features([...])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4290d7-b84e-42f7-be28-583867467196",
   "metadata": {},
   "source": [
    "Fill in the code to retrieve the jpg file on the trident_processed_no_pen folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dda41a1-0802-4adb-88ae-8c0a09caccc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=[...])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd0c435-6914-40ab-85ce-05e36e449603",
   "metadata": {},
   "source": [
    "How many tiles were encoded for this slide? How many where removed compared to the classical segmentation? Are the tiles at the same coordinates?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338c0b54-af97-47c3-a19d-33f616cd127f",
   "metadata": {},
   "source": [
    "## 4. Slide embedding\n",
    "This step will transform the tiles into vector representations: the tile embeddings.\n",
    "Note that if you use the Trident repo on your own later on, you can also do this step with a batch of WSIs with the following command line:\n",
    "`python run_batch_of_slides.py --task feat --wsi_dir your/wsi/dir --job_dir your/output/dir --mag 20 --patch_size 512 --slide_encoder titan`\n",
    "This will create slide embeddings using the foundation model Titan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fb490f-8ba0-41e0-bb7f-2bade6f4aeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trident.slide_encoder_models.load import encoder_factory\n",
    "slides_path = f\"{coords_dir}/slide_features_feather\"\n",
    "slide_encoder = encoder_factory(\"feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f8df01-04eb-4a91-9bb9-81206e9c78bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "slide.extract_slide_features(\n",
    "    patch_features_path=tiles_path,\n",
    "    slide_encoder=slide_encoder,\n",
    "    save_features=slides_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2caf76b-f8ba-4a53-bff2-aa5a5cff0b3e",
   "metadata": {},
   "source": [
    "Now, let's look at the content of the folder `slides_path`. What is there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021356d1-9791-483e-b792-e7a2a9abe9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ./trident_processed/20x_512px_0px_overlap/slide_features_feather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85337966-0008-47c7-b9d5-f596c1d3b763",
   "metadata": {},
   "source": [
    "Let's look inside the h5 file listed above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8313bf0e-3996-445c-a0cf-dcc959de9ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from lovely_numpy import lo\n",
    "\n",
    "with h5py.File([...]) as f: # Add the h5 filename you found above\n",
    "    feats = f[\"features\"][:] # Extract the slide embedding as a numpy array\n",
    "    print(lo(feats))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23646bb5-2e53-4e47-8212-fbb78889aec4",
   "metadata": {},
   "source": [
    "What is the dimensionality of the obtained representation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1fb313-23f8-46f0-bf14-8c5baac28fde",
   "metadata": {},
   "source": [
    "Now let's extract the slide features for tile embeddings without holes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c40cff-c1e9-4819-8f82-5dd0b3abf21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here put the code to compute the slide embeddings using the segmentation where holes are removed\n",
    "slides_path_no_holes = [...]\n",
    "slide_no_holes.extract_slide_features([...])\n",
    "!ls ./trident_processed_no_holes/20x_512px_0px_overlap/slide_features_feather\n",
    "with h5py.File([...]) as f: # Add the h5 filename you found above\n",
    "    feats_no_holes = f[\"features\"][:] # Extract the slide embedding as a numpy array\n",
    "print(lo(feats_no_holes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae41421-7bff-4e3e-82e3-711818a40fde",
   "metadata": {},
   "source": [
    "Now let's extract the slide features for tile embeddings without penmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c8c8cc-971c-49d8-a266-c3d99b13312e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here put the code to compute the slide embeddings using the segmentation where penmarks are removed\n",
    "slides_path_no_pen = [...]\n",
    "slide_no_pen.extract_slide_features([...])\n",
    "!ls ./trident_processed_no_pen/20x_512px_0px_overlap/slide_features_feather\n",
    "with h5py.File([...]) as f: # Add the h5 filename you found above\n",
    "    feats_no_pen = f[\"features\"][:] # Extract the slide embedding as a numpy array\n",
    "print(lo(feats_no_pen))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dafba6-ad26-4c19-82fa-ffef9f1e57ca",
   "metadata": {},
   "source": [
    "Now let's compare these representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5373a79-dab7-4721-9964-d305ec175783",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "cosine_similarity(np.array([feats, feats_no_holes, feats_no_pen]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92843b18-0ca8-4632-bc00-0db796fafac2",
   "metadata": {},
   "source": [
    "How high is the similarity between the different slide embeddings? Did the different segmentation methods impact the slide representation?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (MG_AI)",
   "language": "python",
   "name": "mg_ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
